# PPO Configuration for Quantum Device Environment

# Environment settings
env:
  name: "QuantumDeviceEnv"
  config_path: "../env_config.yaml"
  render_mode: "human"

# Network architecture
network:
  # Image processing (CNN)
  image_shape: [64, 64, 1]  # [height, width, channels]
  cnn_hidden_dim: 64
  cnn_output_dim: 64
  
  # Voltage processing (MLP)
  voltage_dim: 2
  voltage_hidden_dim: 32
  
  # Fusion and output
  fusion_hidden_dim: 128
  action_dim: 2
  
  # Network type: "separate" or "shared"
  architecture: "shared"  # Use shared feature extractors

# PPO hyperparameters
ppo:
  # Training
  total_timesteps: 1000
  timesteps_per_batch: 2048
  max_timesteps_per_episode: 500
  updates_per_iteration: 10
  
  # Learning rates
  actor_lr: 3e-4
  critic_lr: 1e-3
  
  # PPO specific
  epsilon: 0.2  # Clipping parameter
  gamma: 0.99   # Discount factor
  gae_lambda: 0.95  # GAE lambda
  
  # Value function
  value_clip_ratio: 0.2
  
  # Policy
  entropy_coef: 0.01  # Entropy bonus coefficient
  max_kl_div: 0.01    # Early stopping KL divergence threshold
  
  # Normalization
  normalize_advantages: true
  normalize_observations: false  # Environment handles this

# Optimization
optimization:
  # Adam optimizer
  beta1: 0.9
  beta2: 0.999
  eps: 1e-8
  
  # Gradient clipping
  max_grad_norm: 0.5

# Logging and evaluation
logging:
  log_interval: 10  # Log every N iterations
  eval_interval: 50  # Evaluate every N iterations
  save_interval: 100  # Save model every N iterations
  
  # Tensorboard
  tensorboard_log: "./logs/ppo_quantum_device"
  
  # Model saving
  model_dir: "./models"
  save_best_only: true

# Device settings
device:
  use_cuda: true
  device_id: 0

# Debug settings
debug:
  verbose: true
  print_network_info: true
  validate_observations: true 